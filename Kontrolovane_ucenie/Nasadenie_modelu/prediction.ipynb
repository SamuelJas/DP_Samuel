{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python notebook \n",
    "V nasledujúcom notebooku sú popísané Python metódy použité pre analýzu dát. Obsah notebooku je nasledujúci:\n",
    "1. Import potrebných knižníc\n",
    "2. Spracovanie dát z YOLO výstupu\n",
    "3. Predikcia modelom pre klasifikáciu disperzií\n",
    "4. Vytvorenie konečnej výstupnej tabuľky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import potrebných knižníc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (3.3.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (8.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (5.3.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.5.3)\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.7.0)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (0.8.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (4.54.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (0.11.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 18)) (1.1.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "Collecting opencv-python>=4.1.2\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.5 MB 60.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 18)) (2020.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
      "Collecting pdf2image>=1.16.0\n",
      "  Downloading pdf2image-1.16.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (8.0.1)\n",
      "Collecting PyPDF2>=1.26.0\n",
      "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.5.3)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (3.3.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 18)) (1.1.5)\n",
      "Collecting tensorboard>=2.4.1\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 55.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (3.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (49.6.0.post20201009)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.34.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (0.36.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.7.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.23.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (0.11.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (2.25.0)\n",
      "Collecting thop\n",
      "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.7.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.0->-r requirements.txt (line 8)) (3.7.4.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.7.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (8.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.15.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.15.0)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 73.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 13)) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 13)) (4.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (49.6.0.post20201009)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 13)) (0.2.8)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.23.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.3.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.15.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (49.6.0.post20201009)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 13)) (0.4.8)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 13)) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 13)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 13)) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 13)) (1.25.11)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 13)) (3.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 13)) (2.25.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 13)) (0.4.8)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 63.0 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: PyPDF2, future\n",
      "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61086 sha256=d7ad3d3b90ddfff60bdabc4d38d4022945fa76410dcc6f7f3337bc3dce9ecb74\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/b1/1a/8f/a4c34be976825a2f7948d0fa40907598d69834f8ab5889de11\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=53440820352bbe9d6e224745d7f772fdb13a5cafc7f3560ba47e2ac620c6be15\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built PyPDF2 future\n",
      "Installing collected packages: future, dataclasses, tensorboard-data-server, thop, tensorboard, PyPDF2, pdf2image, opencv-python\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.4.0\n",
      "    Uninstalling tensorboard-2.4.0:\n",
      "      Successfully uninstalled tensorboard-2.4.0\n",
      "Successfully installed PyPDF2-1.26.0 dataclasses-0.6 future-0.18.2 opencv-python-4.5.5.64 pdf2image-1.16.0 tensorboard-2.8.0 tensorboard-data-server-0.6.1 thop-0.0.31.post2005241907\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import operator\n",
    "from skimage.io import imread\n",
    "from PIL import Image, ImageDraw\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow, show\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcia na odstránenie udalostí, ktoré YOLO detegovalo ako tweek a aj ako sferik. Predpoklad vymazania udalosti je\n",
    "#detekovanie v rovnakej milisekunde\n",
    "#odstraňuje sa udalosť typu sferik v tabuľky\n",
    "def clear_duplicate(df):\n",
    "    mil=[]\n",
    "    tweek=[]\n",
    "    for i in df['milisecond']:\n",
    "        mil.append(i)\n",
    "\n",
    "    for i in df['tweek']:\n",
    "        tweek.append(i)\n",
    "\n",
    "    for index, elem in enumerate(mil):\n",
    "        if (index+1 <= len(mil) and index - 1 >= 0):\n",
    "            prev_el = str(mil[index-1])\n",
    "            curr_el = str(elem)\n",
    "            if prev_el == curr_el:\n",
    "                if tweek[index]>tweek[index-1]:\n",
    "                    df=df.drop(df.index[index-1])\n",
    "                    mil.pop(index-1)\n",
    "                    tweek.pop(index-1)\n",
    "                else:\n",
    "                    df=df.drop(df.index[index])\n",
    "                    mil.pop(index)\n",
    "                    tweek.pop(index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Spracovanie dát z YOLO výstupu\n",
    "Z YOLO detekcie extrahujeme nájdené udalosti podľa typu (tweek, sferik) a udalosti typu tweek ďalej klasifikujeme podľa počtu disperzií."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path - spracované surové dáta, na ktorých bola použitá YOLO metóda\n",
    "#croppedPath - zložka, kam sa majú uložiť extrahované sferiky\n",
    "#rootPath - zložka s označením tried YOLO metódou (label dát)\n",
    "#imgNR - poradové číslo udalosti\n",
    "imagePath= r'/home/jovyan/data/lightning/Samuel/git/tweeks_detection/files/2016_Data/2016_Img'\n",
    "croppedPath = r'/home/jovyan/data/lightning/Samuel/git/tweeks_detection/files/2016_Data/2016_Cropped/2016_Cropped_S'\n",
    "rootPath = r'/home/jovyan/data/lightning/Samuel/git/tweeks_detection/yolov5/runs/detect/2016/labels'\n",
    "path = \"\"\n",
    "imageNR=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Udalosti typu sferik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrahuje sferiky a vytvorí čiastkovú výstupnú tab. sferikov output_S.csv\n",
    "with open(os.path.join(\"output_S_2016.csv\"), \"w\") as outputCsv:    \n",
    "    fieldnamesOutput = ['image','event', 'date', 'second', 'milisecond', 'tweek', 'f_min<2kHz', 'tweek_sign']\n",
    "    tableWriter = csv.DictWriter(outputCsv, fieldnames=fieldnamesOutput, delimiter=',')\n",
    "    tableWriter.writeheader()\n",
    "    \n",
    "    for root, dirs, files in os.walk(rootPath):\n",
    "        for file in files:\n",
    "            with open(os.path.join(root, file), \"r\") as csv_file:\n",
    "                reader = csv.reader(csv_file, delimiter=' ')\n",
    "                sortedlist = sorted(reader, key=operator.itemgetter(1))\n",
    "            with open(os.path.join(root, file), \"w\") as csv_file1:\n",
    "                writer = csv.writer(csv_file1, delimiter=' ')\n",
    "                writer.writerows(sortedlist)\n",
    "\n",
    "            with open(os.path.join(root, file), \"r\") as coordFile:\n",
    "\n",
    "                fieldnamesCoords = ['label','x', 'y', 'width', 'height', 'conf']\n",
    "                eventNR=1\n",
    "                coordReader = csv.DictReader(coordFile, fieldnames=fieldnamesCoords, delimiter=' ')\n",
    "                try:\n",
    "                    img = Image.open(os.path.join(imagePath, file.split(\".\")[0]+\".jpg\"))\n",
    "                except:\n",
    "                    break\n",
    "                w, h = img.size\n",
    "                widthms=w/1000\n",
    "\n",
    "                for row in coordReader:\n",
    "                    if row['label'] == \"0\":\n",
    "                        if row['conf'] > \"0.01\":\n",
    "                            widthCoord=round(float(row['width'])*w)\n",
    "                            xCoord=round((float(row['x'])*w)-(float(widthCoord)/2))\n",
    "                            im = img.crop((xCoord, 0, xCoord+widthCoord, 162)).save(os.path.join(croppedPath, file.split(\".\")[0]+\"-S%d.jpg\"%eventNR))\n",
    "                            image = file.split(\".\")[0]+\"-S%d.jpg\"%eventNR\n",
    "                            im2 = img.crop((xCoord, 0, xCoord+widthCoord, 162)).save(os.path.join(root, \"1.jpg\"))\n",
    "                        \n",
    "                            red = imread(os.path.join(root, \"1.jpg\"))[:, :, 0]\n",
    "                            os.remove(os.path.join(root, \"1.jpg\"))\n",
    "\n",
    "                            red=np.delete(red,len(red)-1,0)\n",
    "                            red=np.delete(red,len(red)-1,0)\n",
    "\n",
    "                            transposered=np.transpose(red)\n",
    "\n",
    "                            middle=0\n",
    "                            indexOfMid=0\n",
    "                            currentIndex=1\n",
    "                            for i in transposered:\n",
    "                                if sum(i) > middle:\n",
    "                                    middle=sum(i)\n",
    "                                    indexOfMid=currentIndex\n",
    "                                currentIndex+=1\n",
    "\n",
    "                            milsec=round((indexOfMid+xCoord)/widthms)\n",
    "                        \n",
    "                            j=0\n",
    "                            celyobr=0\n",
    "                            konec=0\n",
    "                            while(j<160):\n",
    "                                celyobr+=sum(red[j])\n",
    "                                if j>138:\n",
    "                                    konec+=sum(red[j])\n",
    "\n",
    "                                j+=1\n",
    "\n",
    "                            if (float((konec*100)/celyobr))>9.5:\n",
    "                                vysledok=1\n",
    "                            else: vysledok=0\n",
    "                            \n",
    "                        \n",
    "                            tableWriter.writerow({\n",
    "                                'image':image, \n",
    "                                'event':eventNR, \n",
    "                                'date':file[4:19], \n",
    "                                'second':file[file.find(\"s\")+1:file.find(\".txt\")], \n",
    "                                'milisecond':milsec, \n",
    "                                'tweek':row['label'], \n",
    "                                'f_min<2kHz':vysledok,\n",
    "                                'tweek_sign':'0'})\n",
    "                            eventNR+=1\n",
    "                            #print(row)\n",
    "                        imageNR+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path - spracované surové dáta, na ktorých bola použitá YOLO metóda\n",
    "#croppedPath - zložka, kam sa majú uložiť extrahované tweeky\n",
    "#rootPath - zložka s označením tried YOLO metódou (label dát)\n",
    "#imgNR - poradove číslo udalosti\n",
    "#imagePath= r'/home/jovyan/data/lightning/Samuel/git/tweeks_detection/files/pred_img'\n",
    "croppedPath = r'/home/jovyan/data/lightning/Samuel/git/tweeks_detection/files/2016_Data/2016_Cropped/2016_Cropped_T'\n",
    "#rootPath = r'/home/jovyan/data/lightning/Samuel/git/tweeks_detection/yolov5/runs/detect/exp/labels'\n",
    "path = \"\"\n",
    "imageNR=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Udalosti typu tweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrahuje tweeky a vytvorí čiastkovú výstupnú tab. tweekov output_T.csv\n",
    "with open(os.path.join(\"output_T_2016.csv\"), \"w\") as outputCsv:    \n",
    "    fieldnamesOutput = ['image','event', 'date', 'second', 'milisecond', 'tweek', 'f_min<2kHz']\n",
    "    tableWriter = csv.DictWriter(outputCsv, fieldnames=fieldnamesOutput, delimiter=',')\n",
    "    tableWriter.writeheader()\n",
    "    \n",
    "    for root, dirs, files in os.walk(rootPath):\n",
    "        for file in files:\n",
    "            with open(os.path.join(root, file), \"r\") as csv_file:\n",
    "                reader = csv.reader(csv_file, delimiter=' ')\n",
    "                sortedlist = sorted(reader, key=operator.itemgetter(1))\n",
    "            with open(os.path.join(root, file), \"w\") as csv_file1:\n",
    "                writer = csv.writer(csv_file1, delimiter=' ')\n",
    "                writer.writerows(sortedlist)\n",
    "\n",
    "            with open(os.path.join(root, file), \"r\") as coordFile:\n",
    "\n",
    "                fieldnamesCoords = ['label','x', 'y', 'width', 'height', 'conf']\n",
    "                eventNR=1\n",
    "                coordReader = csv.DictReader(coordFile, fieldnames=fieldnamesCoords, delimiter=' ')\n",
    "                try:\n",
    "                    img = Image.open(os.path.join(imagePath, file.split(\".\")[0]+\".jpg\"))\n",
    "                except:\n",
    "                    break\n",
    "                w, h = img.size\n",
    "                widthms=w/1000\n",
    "\n",
    "                for row in coordReader:\n",
    "                    if row['label'] == \"1\":\n",
    "                        widthCoord=round(float(row['width'])*w)\n",
    "                        xCoord=round((float(row['x'])*w)-(float(widthCoord)/2))\n",
    "                        im = img.crop((xCoord, 0, xCoord+widthCoord, 162)).save(os.path.join(croppedPath, file.split(\".\")[0]+\"-T%d.jpg\"%eventNR))\n",
    "                        image = file.split(\".\")[0]+\"-T%d.jpg\"%eventNR\n",
    "                        im2 = img.crop((xCoord, 0, xCoord+widthCoord, 162)).save(os.path.join(root, \"1.jpg\"))\n",
    "                        \n",
    "                        red = imread(os.path.join(root, \"1.jpg\"))[:, :, 0]\n",
    "                        os.remove(os.path.join(root, \"1.jpg\"))\n",
    "\n",
    "                        red=np.delete(red,len(red)-1,0)\n",
    "                        red=np.delete(red,len(red)-1,0)\n",
    "\n",
    "                        transposered=np.transpose(red)\n",
    "\n",
    "                        middle=0\n",
    "                        indexOfMid=0\n",
    "                        currentIndex=1\n",
    "                        for i in transposered:\n",
    "                            if sum(i) > middle:\n",
    "                                middle=sum(i)\n",
    "                                indexOfMid=currentIndex\n",
    "                            currentIndex+=1\n",
    "\n",
    "                        milsec=round((indexOfMid+xCoord)/widthms)\n",
    "                        \n",
    "                        j=0\n",
    "                        celyobr=0\n",
    "                        konec=0\n",
    "                        while(j<160):\n",
    "                            celyobr+=sum(red[j])\n",
    "                            if j>138:\n",
    "                                konec+=sum(red[j])\n",
    "\n",
    "                            j+=1\n",
    "\n",
    "                        if (float((konec*100)/celyobr))>9.5:\n",
    "                            vysledok=1\n",
    "                        else: vysledok=0\n",
    "                            \n",
    "                        \n",
    "                        tableWriter.writerow({\n",
    "                            'image':image, \n",
    "                            'event':eventNR, \n",
    "                            'date':file[4:19], \n",
    "                            'second':file[file.find(\"s\")+1:file.find(\".txt\")], \n",
    "                            'milisecond':milsec, \n",
    "                            'tweek':row['label'], \n",
    "                            'f_min<2kHz':vysledok})\n",
    "                        eventNR+=1\n",
    "                        #print(row)\n",
    "                    imageNR+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predikcia modelom pre klasifikáciu disperzií\n",
    "\n",
    "Extrahované udalosti typu tweek klasifikujeme vytvoreným model podľa počtu disperzií."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIRECTORY - cesta ku extrahovaným tweekom\n",
    "#model - natrénovaný model klasifikácie disperzií tweekov\n",
    "DIRECTORY = r'/home/jovyan/data/lightning/Samuel/git/tweeks_detection/files/2016_Data/2016_Cropped/2016_Cropped_T'\n",
    "model = load_model('model_datagen_RBG.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spracuje extrahované tweeky do formátu vhodného pre klasifikáciu modelom\n",
    "#na dátach predikuje počet tweek_sign (disperzií)\n",
    "#predikciu spojí s čiastkovou výstupnou tab. output_T.csv, upraví číslovanie predikcií a pridá ich do výst. tab. vyst_tab.csv\n",
    "data2 = []\n",
    "pathvar = []\n",
    "folder = DIRECTORY\n",
    "for img in os.listdir(folder):\n",
    "    img_path = os.path.join(folder, img)\n",
    "    if(img_path == '/home/jovyan/data/lightning/Samuel/git/tweeks_detection/files/2016_Data/2016_Cropped/2016_Cropped_T/.ipynb_checkpoints'):\n",
    "        continue\n",
    "    #print(img_path)\n",
    "    img_arr = cv2.imread(img_path)\n",
    "    img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "    img_arr = cv2.resize(img_arr, (40, 150))\n",
    "    pathvar.append(img)\n",
    "    data2.append(img_arr)\n",
    "    \n",
    "X = []\n",
    "for features in data2:\n",
    "    X.append(features)\n",
    "X = np.asarray(X, dtype=np.float32)/255\n",
    "#X = np.array(X)\n",
    "#X = X/255\n",
    "pathvar = np.array(pathvar)\n",
    "\n",
    "predictions = model.predict_classes(X, batch_size = 30)\n",
    "#print(predictions)\n",
    "\n",
    "df = pd.DataFrame(list(zip(pathvar, predictions)), columns =['image', 'tweek_sign'])\n",
    "\n",
    "output = pd.read_csv('output_T_2016.csv')\n",
    "\n",
    "final = pd.merge(output, df, on=\"image\")\n",
    "final['tweek_sign'].replace({0:1, 1:2, 2:3, 3:4}, inplace = True)\n",
    "final.to_csv('vyst_tab_2016.csv', index = False)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Vytvorenie konečnej výstupnej tabuľky\n",
    "\n",
    "Čiastkové výstupné tabuľky spojíme do konečnej výstupnej tabuľky s názvom result. Konečnú výstupnú tabuľku usporiadame aby udalosti išli za sebou ako boli detegované a očistíme tabuľku od duplikátov funkciou, ktorú sme definovali na začiatku notebooku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spojí čiastkové výst. tab. sferikov output_S.csv a tweekov vyst_tab.csv\n",
    "df1 = pd.read_csv(\"output_S_2016.csv\", low_memory=False)\n",
    "df2 = pd.read_csv(\"vyst_tab_2016.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vytvorí nový stĺpec s názvom pôvodného spektrogramu, z ktorého udalosť pochádza\n",
    "#usporiada hodnoty najprv podľa pôvodného spektrogramu 'org_img' a potom podľa milisekundy 'milisecond'\n",
    "#upraví indexovanie\n",
    "result['org_img'] = result['image'].str.split('-', 1).str[0]\n",
    "result = result[['org_img', 'image', 'event', 'date', 'second', 'milisecond', 'tweek', 'f_min<2kHz', 'tweek_sign']]\n",
    "result = result.sort_values(['org_img', 'milisecond'])\n",
    "result = result.reset_index()\n",
    "result = result.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zavolá funkciu na odstránenie duplicitne zaklasifikovaných udalostí\n",
    "result = clear_duplicate(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#celkovú výst. tab. uloží ako csv result.csv\n",
    "result.to_csv('result_2016.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicitné udalosti je možné vymazať zo zložiek, v ktorých sú uložené nasledujúcim kódom. Pre potreby analýzy dát nie je tento krok potrebný. Potrebný je iba vtedy, ak by sme dáta chceli použiť aj pre potreby nekontrolovaného učenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rootPath - cesta ku extrahovaným sferikom\n",
    "#file_name - zoznam súborov, ktoré nechceme vymazať (názov img zhodný z názvom v rootPath)\n",
    "rootPath = r'/home/jovyan/data/lightning/Samuel/git/tweeks_detection/files/2016_Data/2016_Cropped/2016_Cropped_S'\n",
    "file_name = result['image'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/data/lightning/Samuel/git/tweeks_detection/files/2016_Data/2016_Cropped/2016_Cropped_S'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4417696"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prejde uložené obrázky a ak sa obrázok nevyskytuje v zozname file_name, vymaže udalosť zo zložky\n",
    "#maže duplicitne označené udalosti YOLO metódou.\n",
    "for filename in os.listdir(rootPath):\n",
    "    #print(filename)\n",
    "    if filename not in file_name:\n",
    "        if(filename == '.ipynb_checkpoints'):\n",
    "            continue\n",
    "        else:\n",
    "            full_file_path = os.path.join(rootPath, filename)\n",
    "            os.remove(full_file_path)\n",
    "            print(\"removed: \"+filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
